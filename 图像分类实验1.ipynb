{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像分类实验\n",
    "陈乐昕 2020-10-13\n",
    "## 图像处理环境基础\n",
    "图像处理库: opencv, PIL(Pillow)\n",
    "## 建立简单的神经网络\n",
    "有两种方式进行图像的分类实验：\n",
    "- 预训练好神经网络\n",
    "- 自定义神经网络\n",
    "\n",
    "分别以两种方式来做简单的实验\n",
    "\n",
    "## 预训练好的神经网络\n",
    "这种方法是定义一些神经网络，并利用imagenet大规模图像集进行训练，训练好的网络的权重可以下载。 具体的模型的定义请参考：\n",
    "https://github.com/pytorch/vision/tree/master/torchvision/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 定义好的网络结构，并加载训练好的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 定义好的网络结构\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50.load_state_dict(torch.load('C:\\\\Users\\\\Doiya\\\\.cache\\\\torch\\\\hub\\\\checkpoints\\\\resnet50-19c8e357.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 显示网络结构，看看具体的结构\n",
    "print(resnet50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"./2.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "transform = transforms.Compose([            #[1]\n",
    " transforms.Resize(256),                    #[2]\n",
    " transforms.CenterCrop(224),                #[3]\n",
    " transforms.ToTensor(),                     #[4]\n",
    " transforms.Normalize(                      #[5]\n",
    " mean=[0.485, 0.456, 0.406],                #[6]\n",
    " std=[0.229, 0.224, 0.225]                  #[7]\n",
    " )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_t=torch.unsqueeze(img_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "resnet50.eval()\n",
    "out = resnet50(b_t)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_classes.txt') as f:\n",
    "  classes = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0, tench',\n",
       " '1, goldfish',\n",
       " '2, great_white_shark',\n",
       " '3, tiger_shark',\n",
       " '4, hammerhead',\n",
       " '5, electric_ray',\n",
       " '6, stingray',\n",
       " '7, cock',\n",
       " '8, hen',\n",
       " '9, ostrich',\n",
       " '10, brambling',\n",
       " '11, goldfinch',\n",
       " '12, house_finch',\n",
       " '13, junco',\n",
       " '14, indigo_bunting',\n",
       " '15, robin',\n",
       " '16, bulbul',\n",
       " '17, jay',\n",
       " '18, magpie',\n",
       " '19, chickadee',\n",
       " '20, water_ouzel',\n",
       " '21, kite',\n",
       " '22, bald_eagle',\n",
       " '23, vulture',\n",
       " '24, great_grey_owl',\n",
       " '25, European_fire_salamander',\n",
       " '26, common_newt',\n",
       " '27, eft',\n",
       " '28, spotted_salamander',\n",
       " '29, axolotl',\n",
       " '30, bullfrog',\n",
       " '31, tree_frog',\n",
       " '32, tailed_frog',\n",
       " '33, loggerhead',\n",
       " '34, leatherback_turtle',\n",
       " '35, mud_turtle',\n",
       " '36, terrapin',\n",
       " '37, box_turtle',\n",
       " '38, banded_gecko',\n",
       " '39, common_iguana',\n",
       " '40, American_chameleon',\n",
       " '41, whiptail',\n",
       " '42, agama',\n",
       " '43, frilled_lizard',\n",
       " '44, alligator_lizard',\n",
       " '45, Gila_monster',\n",
       " '46, green_lizard',\n",
       " '47, African_chameleon',\n",
       " '48, Komodo_dragon',\n",
       " '49, African_crocodile',\n",
       " '50, American_alligator',\n",
       " '51, triceratops',\n",
       " '52, thunder_snake',\n",
       " '53, ringneck_snake',\n",
       " '54, hognose_snake',\n",
       " '55, green_snake',\n",
       " '56, king_snake',\n",
       " '57, garter_snake',\n",
       " '58, water_snake',\n",
       " '59, vine_snake',\n",
       " '60, night_snake',\n",
       " '61, boa_constrictor',\n",
       " '62, rock_python',\n",
       " '63, Indian_cobra',\n",
       " '64, green_mamba',\n",
       " '65, sea_snake',\n",
       " '66, horned_viper',\n",
       " '67, diamondback',\n",
       " '68, sidewinder',\n",
       " '69, trilobite',\n",
       " '70, harvestman',\n",
       " '71, scorpion',\n",
       " '72, black_and_gold_garden_spider',\n",
       " '73, barn_spider',\n",
       " '74, garden_spider',\n",
       " '75, black_widow',\n",
       " '76, tarantula',\n",
       " '77, wolf_spider',\n",
       " '78, tick',\n",
       " '79, centipede',\n",
       " '80, black_grouse',\n",
       " '81, ptarmigan',\n",
       " '82, ruffed_grouse',\n",
       " '83, prairie_chicken',\n",
       " '84, peacock',\n",
       " '85, quail',\n",
       " '86, partridge',\n",
       " '87, African_grey',\n",
       " '88, macaw',\n",
       " '89, sulphur-crested_cockatoo',\n",
       " '90, lorikeet',\n",
       " '91, coucal',\n",
       " '92, bee_eater',\n",
       " '93, hornbill',\n",
       " '94, hummingbird',\n",
       " '95, jacamar',\n",
       " '96, toucan',\n",
       " '97, drake',\n",
       " '98, red-breasted_merganser',\n",
       " '99, goose',\n",
       " '100, black_swan',\n",
       " '101, tusker',\n",
       " '102, echidna',\n",
       " '103, platypus',\n",
       " '104, wallaby',\n",
       " '105, koala',\n",
       " '106, wombat',\n",
       " '107, jellyfish',\n",
       " '108, sea_anemone',\n",
       " '109, brain_coral',\n",
       " '110, flatworm',\n",
       " '111, nematode',\n",
       " '112, conch',\n",
       " '113, snail',\n",
       " '114, slug',\n",
       " '115, sea_slug',\n",
       " '116, chiton',\n",
       " '117, chambered_nautilus',\n",
       " '118, Dungeness_crab',\n",
       " '119, rock_crab',\n",
       " '120, fiddler_crab',\n",
       " '121, king_crab',\n",
       " '122, American_lobster',\n",
       " '123, spiny_lobster',\n",
       " '124, crayfish',\n",
       " '125, hermit_crab',\n",
       " '126, isopod',\n",
       " '127, white_stork',\n",
       " '128, black_stork',\n",
       " '129, spoonbill',\n",
       " '130, flamingo',\n",
       " '131, little_blue_heron',\n",
       " '132, American_egret',\n",
       " '133, bittern',\n",
       " '134, crane',\n",
       " '135, limpkin',\n",
       " '136, European_gallinule',\n",
       " '137, American_coot',\n",
       " '138, bustard',\n",
       " '139, ruddy_turnstone',\n",
       " '140, red-backed_sandpiper',\n",
       " '141, redshank',\n",
       " '142, dowitcher',\n",
       " '143, oystercatcher',\n",
       " '144, pelican',\n",
       " '145, king_penguin',\n",
       " '146, albatross',\n",
       " '147, grey_whale',\n",
       " '148, killer_whale',\n",
       " '149, dugong',\n",
       " '150, sea_lion',\n",
       " '151, Chihuahua',\n",
       " '152, Japanese_spaniel',\n",
       " '153, Maltese_dog',\n",
       " '154, Pekinese',\n",
       " '155, Shih-Tzu',\n",
       " '156, Blenheim_spaniel',\n",
       " '157, papillon',\n",
       " '158, toy_terrier',\n",
       " '159, Rhodesian_ridgeback',\n",
       " '160, Afghan_hound',\n",
       " '161, basset',\n",
       " '162, beagle',\n",
       " '163, bloodhound',\n",
       " '164, bluetick',\n",
       " '165, black-and-tan_coonhound',\n",
       " '166, Walker_hound',\n",
       " '167, English_foxhound',\n",
       " '168, redbone',\n",
       " '169, borzoi',\n",
       " '170, Irish_wolfhound',\n",
       " '171, Italian_greyhound',\n",
       " '172, whippet',\n",
       " '173, Ibizan_hound',\n",
       " '174, Norwegian_elkhound',\n",
       " '175, otterhound',\n",
       " '176, Saluki',\n",
       " '177, Scottish_deerhound',\n",
       " '178, Weimaraner',\n",
       " '179, Staffordshire_bullterrier',\n",
       " '180, American_Staffordshire_terrier',\n",
       " '181, Bedlington_terrier',\n",
       " '182, Border_terrier',\n",
       " '183, Kerry_blue_terrier',\n",
       " '184, Irish_terrier',\n",
       " '185, Norfolk_terrier',\n",
       " '186, Norwich_terrier',\n",
       " '187, Yorkshire_terrier',\n",
       " '188, wire-haired_fox_terrier',\n",
       " '189, Lakeland_terrier',\n",
       " '190, Sealyham_terrier',\n",
       " '191, Airedale',\n",
       " '192, cairn',\n",
       " '193, Australian_terrier',\n",
       " '194, Dandie_Dinmont',\n",
       " '195, Boston_bull',\n",
       " '196, miniature_schnauzer',\n",
       " '197, giant_schnauzer',\n",
       " '198, standard_schnauzer',\n",
       " '199, Scotch_terrier',\n",
       " '200, Tibetan_terrier',\n",
       " '201, silky_terrier',\n",
       " '202, soft-coated_wheaten_terrier',\n",
       " '203, West_Highland_white_terrier',\n",
       " '204, Lhasa',\n",
       " '205, flat-coated_retriever',\n",
       " '206, curly-coated_retriever',\n",
       " '207, golden_retriever',\n",
       " '208, Labrador_retriever',\n",
       " '209, Chesapeake_Bay_retriever',\n",
       " '210, German_short-haired_pointer',\n",
       " '211, vizsla',\n",
       " '212, English_setter',\n",
       " '213, Irish_setter',\n",
       " '214, Gordon_setter',\n",
       " '215, Brittany_spaniel',\n",
       " '216, clumber',\n",
       " '217, English_springer',\n",
       " '218, Welsh_springer_spaniel',\n",
       " '219, cocker_spaniel',\n",
       " '220, Sussex_spaniel',\n",
       " '221, Irish_water_spaniel',\n",
       " '222, kuvasz',\n",
       " '223, schipperke',\n",
       " '224, groenendael',\n",
       " '225, malinois',\n",
       " '226, briard',\n",
       " '227, kelpie',\n",
       " '228, komondor',\n",
       " '229, Old_English_sheepdog',\n",
       " '230, Shetland_sheepdog',\n",
       " '231, collie',\n",
       " '232, Border_collie',\n",
       " '233, Bouvier_des_Flandres',\n",
       " '234, Rottweiler',\n",
       " '235, German_shepherd',\n",
       " '236, Doberman',\n",
       " '237, miniature_pinscher',\n",
       " '238, Greater_Swiss_Mountain_dog',\n",
       " '239, Bernese_mountain_dog',\n",
       " '240, Appenzeller',\n",
       " '241, EntleBucher',\n",
       " '242, boxer',\n",
       " '243, bull_mastiff',\n",
       " '244, Tibetan_mastiff',\n",
       " '245, French_bulldog',\n",
       " '246, Great_Dane',\n",
       " '247, Saint_Bernard',\n",
       " '248, Eskimo_dog',\n",
       " '249, malamute',\n",
       " '250, Siberian_husky',\n",
       " '251, dalmatian',\n",
       " '252, affenpinscher',\n",
       " '253, basenji',\n",
       " '254, pug',\n",
       " '255, Leonberg',\n",
       " '256, Newfoundland',\n",
       " '257, Great_Pyrenees',\n",
       " '258, Samoyed',\n",
       " '259, Pomeranian',\n",
       " '260, chow',\n",
       " '261, keeshond',\n",
       " '262, Brabancon_griffon',\n",
       " '263, Pembroke',\n",
       " '264, Cardigan',\n",
       " '265, toy_poodle',\n",
       " '266, miniature_poodle',\n",
       " '267, standard_poodle',\n",
       " '268, Mexican_hairless',\n",
       " '269, timber_wolf',\n",
       " '270, white_wolf',\n",
       " '271, red_wolf',\n",
       " '272, coyote',\n",
       " '273, dingo',\n",
       " '274, dhole',\n",
       " '275, African_hunting_dog',\n",
       " '276, hyena',\n",
       " '277, red_fox',\n",
       " '278, kit_fox',\n",
       " '279, Arctic_fox',\n",
       " '280, grey_fox',\n",
       " '281, tabby',\n",
       " '282, tiger_cat',\n",
       " '283, Persian_cat',\n",
       " '284, Siamese_cat',\n",
       " '285, Egyptian_cat',\n",
       " '286, cougar',\n",
       " '287, lynx',\n",
       " '288, leopard',\n",
       " '289, snow_leopard',\n",
       " '290, jaguar',\n",
       " '291, lion',\n",
       " '292, tiger',\n",
       " '293, cheetah',\n",
       " '294, brown_bear',\n",
       " '295, American_black_bear',\n",
       " '296, ice_bear',\n",
       " '297, sloth_bear',\n",
       " '298, mongoose',\n",
       " '299, meerkat',\n",
       " '300, tiger_beetle',\n",
       " '301, ladybug',\n",
       " '302, ground_beetle',\n",
       " '303, long-horned_beetle',\n",
       " '304, leaf_beetle',\n",
       " '305, dung_beetle',\n",
       " '306, rhinoceros_beetle',\n",
       " '307, weevil',\n",
       " '308, fly',\n",
       " '309, bee',\n",
       " '310, ant',\n",
       " '311, grasshopper',\n",
       " '312, cricket',\n",
       " '313, walking_stick',\n",
       " '314, cockroach',\n",
       " '315, mantis',\n",
       " '316, cicada',\n",
       " '317, leafhopper',\n",
       " '318, lacewing',\n",
       " '319, dragonfly',\n",
       " '320, damselfly',\n",
       " '321, admiral',\n",
       " '322, ringlet',\n",
       " '323, monarch',\n",
       " '324, cabbage_butterfly',\n",
       " '325, sulphur_butterfly',\n",
       " '326, lycaenid',\n",
       " '327, starfish',\n",
       " '328, sea_urchin',\n",
       " '329, sea_cucumber',\n",
       " '330, wood_rabbit',\n",
       " '331, hare',\n",
       " '332, Angora',\n",
       " '333, hamster',\n",
       " '334, porcupine',\n",
       " '335, fox_squirrel',\n",
       " '336, marmot',\n",
       " '337, beaver',\n",
       " '338, guinea_pig',\n",
       " '339, sorrel',\n",
       " '340, zebra',\n",
       " '341, hog',\n",
       " '342, wild_boar',\n",
       " '343, warthog',\n",
       " '344, hippopotamus',\n",
       " '345, ox',\n",
       " '346, water_buffalo',\n",
       " '347, bison',\n",
       " '348, ram',\n",
       " '349, bighorn',\n",
       " '350, ibex',\n",
       " '351, hartebeest',\n",
       " '352, impala',\n",
       " '353, gazelle',\n",
       " '354, Arabian_camel',\n",
       " '355, llama',\n",
       " '356, weasel',\n",
       " '357, mink',\n",
       " '358, polecat',\n",
       " '359, black-footed_ferret',\n",
       " '360, otter',\n",
       " '361, skunk',\n",
       " '362, badger',\n",
       " '363, armadillo',\n",
       " '364, three-toed_sloth',\n",
       " '365, orangutan',\n",
       " '366, gorilla',\n",
       " '367, chimpanzee',\n",
       " '368, gibbon',\n",
       " '369, siamang',\n",
       " '370, guenon',\n",
       " '371, patas',\n",
       " '372, baboon',\n",
       " '373, macaque',\n",
       " '374, langur',\n",
       " '375, colobus',\n",
       " '376, proboscis_monkey',\n",
       " '377, marmoset',\n",
       " '378, capuchin',\n",
       " '379, howler_monkey',\n",
       " '380, titi',\n",
       " '381, spider_monkey',\n",
       " '382, squirrel_monkey',\n",
       " '383, Madagascar_cat',\n",
       " '384, indri',\n",
       " '385, Indian_elephant',\n",
       " '386, African_elephant',\n",
       " '387, lesser_panda',\n",
       " '388, giant_panda',\n",
       " '389, barracouta',\n",
       " '390, eel',\n",
       " '391, coho',\n",
       " '392, rock_beauty',\n",
       " '393, anemone_fish',\n",
       " '394, sturgeon',\n",
       " '395, gar',\n",
       " '396, lionfish',\n",
       " '397, puffer',\n",
       " '398, abacus',\n",
       " '399, abaya',\n",
       " '400, academic_gown',\n",
       " '401, accordion',\n",
       " '402, acoustic_guitar',\n",
       " '403, aircraft_carrier',\n",
       " '404, airliner',\n",
       " '405, airship',\n",
       " '406, altar',\n",
       " '407, ambulance',\n",
       " '408, amphibian',\n",
       " '409, analog_clock',\n",
       " '410, apiary',\n",
       " '411, apron',\n",
       " '412, ashcan',\n",
       " '413, assault_rifle',\n",
       " '414, backpack',\n",
       " '415, bakery',\n",
       " '416, balance_beam',\n",
       " '417, balloon',\n",
       " '418, ballpoint',\n",
       " '419, Band_Aid',\n",
       " '420, banjo',\n",
       " '421, bannister',\n",
       " '422, barbell',\n",
       " '423, barber_chair',\n",
       " '424, barbershop',\n",
       " '425, barn',\n",
       " '426, barometer',\n",
       " '427, barrel',\n",
       " '428, barrow',\n",
       " '429, baseball',\n",
       " '430, basketball',\n",
       " '431, bassinet',\n",
       " '432, bassoon',\n",
       " '433, bathing_cap',\n",
       " '434, bath_towel',\n",
       " '435, bathtub',\n",
       " '436, beach_wagon',\n",
       " '437, beacon',\n",
       " '438, beaker',\n",
       " '439, bearskin',\n",
       " '440, beer_bottle',\n",
       " '441, beer_glass',\n",
       " '442, bell_cote',\n",
       " '443, bib',\n",
       " '444, bicycle-built-for-two',\n",
       " '445, bikini',\n",
       " '446, binder',\n",
       " '447, binoculars',\n",
       " '448, birdhouse',\n",
       " '449, boathouse',\n",
       " '450, bobsled',\n",
       " '451, bolo_tie',\n",
       " '452, bonnet',\n",
       " '453, bookcase',\n",
       " '454, bookshop',\n",
       " '455, bottlecap',\n",
       " '456, bow',\n",
       " '457, bow_tie',\n",
       " '458, brass',\n",
       " '459, brassiere',\n",
       " '460, breakwater',\n",
       " '461, breastplate',\n",
       " '462, broom',\n",
       " '463, bucket',\n",
       " '464, buckle',\n",
       " '465, bulletproof_vest',\n",
       " '466, bullet_train',\n",
       " '467, butcher_shop',\n",
       " '468, cab',\n",
       " '469, caldron',\n",
       " '470, candle',\n",
       " '471, cannon',\n",
       " '472, canoe',\n",
       " '473, can_opener',\n",
       " '474, cardigan',\n",
       " '475, car_mirror',\n",
       " '476, carousel',\n",
       " \"477, carpenter's_kit\",\n",
       " '478, carton',\n",
       " '479, car_wheel',\n",
       " '480, cash_machine',\n",
       " '481, cassette',\n",
       " '482, cassette_player',\n",
       " '483, castle',\n",
       " '484, catamaran',\n",
       " '485, CD_player',\n",
       " '486, cello',\n",
       " '487, cellular_telephone',\n",
       " '488, chain',\n",
       " '489, chainlink_fence',\n",
       " '490, chain_mail',\n",
       " '491, chain_saw',\n",
       " '492, chest',\n",
       " '493, chiffonier',\n",
       " '494, chime',\n",
       " '495, china_cabinet',\n",
       " '496, Christmas_stocking',\n",
       " '497, church',\n",
       " '498, cinema',\n",
       " '499, cleaver',\n",
       " '500, cliff_dwelling',\n",
       " '501, cloak',\n",
       " '502, clog',\n",
       " '503, cocktail_shaker',\n",
       " '504, coffee_mug',\n",
       " '505, coffeepot',\n",
       " '506, coil',\n",
       " '507, combination_lock',\n",
       " '508, computer_keyboard',\n",
       " '509, confectionery',\n",
       " '510, container_ship',\n",
       " '511, convertible',\n",
       " '512, corkscrew',\n",
       " '513, cornet',\n",
       " '514, cowboy_boot',\n",
       " '515, cowboy_hat',\n",
       " '516, cradle',\n",
       " '517, crane',\n",
       " '518, crash_helmet',\n",
       " '519, crate',\n",
       " '520, crib',\n",
       " '521, Crock_Pot',\n",
       " '522, croquet_ball',\n",
       " '523, crutch',\n",
       " '524, cuirass',\n",
       " '525, dam',\n",
       " '526, desk',\n",
       " '527, desktop_computer',\n",
       " '528, dial_telephone',\n",
       " '529, diaper',\n",
       " '530, digital_clock',\n",
       " '531, digital_watch',\n",
       " '532, dining_table',\n",
       " '533, dishrag',\n",
       " '534, dishwasher',\n",
       " '535, disk_brake',\n",
       " '536, dock',\n",
       " '537, dogsled',\n",
       " '538, dome',\n",
       " '539, doormat',\n",
       " '540, drilling_platform',\n",
       " '541, drum',\n",
       " '542, drumstick',\n",
       " '543, dumbbell',\n",
       " '544, Dutch_oven',\n",
       " '545, electric_fan',\n",
       " '546, electric_guitar',\n",
       " '547, electric_locomotive',\n",
       " '548, entertainment_center',\n",
       " '549, envelope',\n",
       " '550, espresso_maker',\n",
       " '551, face_powder',\n",
       " '552, feather_boa',\n",
       " '553, file',\n",
       " '554, fireboat',\n",
       " '555, fire_engine',\n",
       " '556, fire_screen',\n",
       " '557, flagpole',\n",
       " '558, flute',\n",
       " '559, folding_chair',\n",
       " '560, football_helmet',\n",
       " '561, forklift',\n",
       " '562, fountain',\n",
       " '563, fountain_pen',\n",
       " '564, four-poster',\n",
       " '565, freight_car',\n",
       " '566, French_horn',\n",
       " '567, frying_pan',\n",
       " '568, fur_coat',\n",
       " '569, garbage_truck',\n",
       " '570, gasmask',\n",
       " '571, gas_pump',\n",
       " '572, goblet',\n",
       " '573, go-kart',\n",
       " '574, golf_ball',\n",
       " '575, golfcart',\n",
       " '576, gondola',\n",
       " '577, gong',\n",
       " '578, gown',\n",
       " '579, grand_piano',\n",
       " '580, greenhouse',\n",
       " '581, grille',\n",
       " '582, grocery_store',\n",
       " '583, guillotine',\n",
       " '584, hair_slide',\n",
       " '585, hair_spray',\n",
       " '586, half_track',\n",
       " '587, hammer',\n",
       " '588, hamper',\n",
       " '589, hand_blower',\n",
       " '590, hand-held_computer',\n",
       " '591, handkerchief',\n",
       " '592, hard_disc',\n",
       " '593, harmonica',\n",
       " '594, harp',\n",
       " '595, harvester',\n",
       " '596, hatchet',\n",
       " '597, holster',\n",
       " '598, home_theater',\n",
       " '599, honeycomb',\n",
       " '600, hook',\n",
       " '601, hoopskirt',\n",
       " '602, horizontal_bar',\n",
       " '603, horse_cart',\n",
       " '604, hourglass',\n",
       " '605, iPod',\n",
       " '606, iron',\n",
       " \"607, jack-o'-lantern\",\n",
       " '608, jean',\n",
       " '609, jeep',\n",
       " '610, jersey',\n",
       " '611, jigsaw_puzzle',\n",
       " '612, jinrikisha',\n",
       " '613, joystick',\n",
       " '614, kimono',\n",
       " '615, knee_pad',\n",
       " '616, knot',\n",
       " '617, lab_coat',\n",
       " '618, ladle',\n",
       " '619, lampshade',\n",
       " '620, laptop',\n",
       " '621, lawn_mower',\n",
       " '622, lens_cap',\n",
       " '623, letter_opener',\n",
       " '624, library',\n",
       " '625, lifeboat',\n",
       " '626, lighter',\n",
       " '627, limousine',\n",
       " '628, liner',\n",
       " '629, lipstick',\n",
       " '630, Loafer',\n",
       " '631, lotion',\n",
       " '632, loudspeaker',\n",
       " '633, loupe',\n",
       " '634, lumbermill',\n",
       " '635, magnetic_compass',\n",
       " '636, mailbag',\n",
       " '637, mailbox',\n",
       " '638, maillot',\n",
       " '639, maillot',\n",
       " '640, manhole_cover',\n",
       " '641, maraca',\n",
       " '642, marimba',\n",
       " '643, mask',\n",
       " '644, matchstick',\n",
       " '645, maypole',\n",
       " '646, maze',\n",
       " '647, measuring_cup',\n",
       " '648, medicine_chest',\n",
       " '649, megalith',\n",
       " '650, microphone',\n",
       " '651, microwave',\n",
       " '652, military_uniform',\n",
       " '653, milk_can',\n",
       " '654, minibus',\n",
       " '655, miniskirt',\n",
       " '656, minivan',\n",
       " '657, missile',\n",
       " '658, mitten',\n",
       " '659, mixing_bowl',\n",
       " '660, mobile_home',\n",
       " '661, Model_T',\n",
       " '662, modem',\n",
       " '663, monastery',\n",
       " '664, monitor',\n",
       " '665, moped',\n",
       " '666, mortar',\n",
       " '667, mortarboard',\n",
       " '668, mosque',\n",
       " '669, mosquito_net',\n",
       " '670, motor_scooter',\n",
       " '671, mountain_bike',\n",
       " '672, mountain_tent',\n",
       " '673, mouse',\n",
       " '674, mousetrap',\n",
       " '675, moving_van',\n",
       " '676, muzzle',\n",
       " '677, nail',\n",
       " '678, neck_brace',\n",
       " '679, necklace',\n",
       " '680, nipple',\n",
       " '681, notebook',\n",
       " '682, obelisk',\n",
       " '683, oboe',\n",
       " '684, ocarina',\n",
       " '685, odometer',\n",
       " '686, oil_filter',\n",
       " '687, organ',\n",
       " '688, oscilloscope',\n",
       " '689, overskirt',\n",
       " '690, oxcart',\n",
       " '691, oxygen_mask',\n",
       " '692, packet',\n",
       " '693, paddle',\n",
       " '694, paddlewheel',\n",
       " '695, padlock',\n",
       " '696, paintbrush',\n",
       " '697, pajama',\n",
       " '698, palace',\n",
       " '699, panpipe',\n",
       " '700, paper_towel',\n",
       " '701, parachute',\n",
       " '702, parallel_bars',\n",
       " '703, park_bench',\n",
       " '704, parking_meter',\n",
       " '705, passenger_car',\n",
       " '706, patio',\n",
       " '707, pay-phone',\n",
       " '708, pedestal',\n",
       " '709, pencil_box',\n",
       " '710, pencil_sharpener',\n",
       " '711, perfume',\n",
       " '712, Petri_dish',\n",
       " '713, photocopier',\n",
       " '714, pick',\n",
       " '715, pickelhaube',\n",
       " '716, picket_fence',\n",
       " '717, pickup',\n",
       " '718, pier',\n",
       " '719, piggy_bank',\n",
       " '720, pill_bottle',\n",
       " '721, pillow',\n",
       " '722, ping-pong_ball',\n",
       " '723, pinwheel',\n",
       " '724, pirate',\n",
       " '725, pitcher',\n",
       " '726, plane',\n",
       " '727, planetarium',\n",
       " '728, plastic_bag',\n",
       " '729, plate_rack',\n",
       " '730, plow',\n",
       " '731, plunger',\n",
       " '732, Polaroid_camera',\n",
       " '733, pole',\n",
       " '734, police_van',\n",
       " '735, poncho',\n",
       " '736, pool_table',\n",
       " '737, pop_bottle',\n",
       " '738, pot',\n",
       " \"739, potter's_wheel\",\n",
       " '740, power_drill',\n",
       " '741, prayer_rug',\n",
       " '742, printer',\n",
       " '743, prison',\n",
       " '744, projectile',\n",
       " '745, projector',\n",
       " '746, puck',\n",
       " '747, punching_bag',\n",
       " '748, purse',\n",
       " '749, quill',\n",
       " '750, quilt',\n",
       " '751, racer',\n",
       " '752, racket',\n",
       " '753, radiator',\n",
       " '754, radio',\n",
       " '755, radio_telescope',\n",
       " '756, rain_barrel',\n",
       " '757, recreational_vehicle',\n",
       " '758, reel',\n",
       " '759, reflex_camera',\n",
       " '760, refrigerator',\n",
       " '761, remote_control',\n",
       " '762, restaurant',\n",
       " '763, revolver',\n",
       " '764, rifle',\n",
       " '765, rocking_chair',\n",
       " '766, rotisserie',\n",
       " '767, rubber_eraser',\n",
       " '768, rugby_ball',\n",
       " '769, rule',\n",
       " '770, running_shoe',\n",
       " '771, safe',\n",
       " '772, safety_pin',\n",
       " '773, saltshaker',\n",
       " '774, sandal',\n",
       " '775, sarong',\n",
       " '776, sax',\n",
       " '777, scabbard',\n",
       " '778, scale',\n",
       " '779, school_bus',\n",
       " '780, schooner',\n",
       " '781, scoreboard',\n",
       " '782, screen',\n",
       " '783, screw',\n",
       " '784, screwdriver',\n",
       " '785, seat_belt',\n",
       " '786, sewing_machine',\n",
       " '787, shield',\n",
       " '788, shoe_shop',\n",
       " '789, shoji',\n",
       " '790, shopping_basket',\n",
       " '791, shopping_cart',\n",
       " '792, shovel',\n",
       " '793, shower_cap',\n",
       " '794, shower_curtain',\n",
       " '795, ski',\n",
       " '796, ski_mask',\n",
       " '797, sleeping_bag',\n",
       " '798, slide_rule',\n",
       " '799, sliding_door',\n",
       " '800, slot',\n",
       " '801, snorkel',\n",
       " '802, snowmobile',\n",
       " '803, snowplow',\n",
       " '804, soap_dispenser',\n",
       " '805, soccer_ball',\n",
       " '806, sock',\n",
       " '807, solar_dish',\n",
       " '808, sombrero',\n",
       " '809, soup_bowl',\n",
       " '810, space_bar',\n",
       " '811, space_heater',\n",
       " '812, space_shuttle',\n",
       " '813, spatula',\n",
       " '814, speedboat',\n",
       " '815, spider_web',\n",
       " '816, spindle',\n",
       " '817, sports_car',\n",
       " '818, spotlight',\n",
       " '819, stage',\n",
       " '820, steam_locomotive',\n",
       " '821, steel_arch_bridge',\n",
       " '822, steel_drum',\n",
       " '823, stethoscope',\n",
       " '824, stole',\n",
       " '825, stone_wall',\n",
       " '826, stopwatch',\n",
       " '827, stove',\n",
       " '828, strainer',\n",
       " '829, streetcar',\n",
       " '830, stretcher',\n",
       " '831, studio_couch',\n",
       " '832, stupa',\n",
       " '833, submarine',\n",
       " '834, suit',\n",
       " '835, sundial',\n",
       " '836, sunglass',\n",
       " '837, sunglasses',\n",
       " '838, sunscreen',\n",
       " '839, suspension_bridge',\n",
       " '840, swab',\n",
       " '841, sweatshirt',\n",
       " '842, swimming_trunks',\n",
       " '843, swing',\n",
       " '844, switch',\n",
       " '845, syringe',\n",
       " '846, table_lamp',\n",
       " '847, tank',\n",
       " '848, tape_player',\n",
       " '849, teapot',\n",
       " '850, teddy',\n",
       " '851, television',\n",
       " '852, tennis_ball',\n",
       " '853, thatch',\n",
       " '854, theater_curtain',\n",
       " '855, thimble',\n",
       " '856, thresher',\n",
       " '857, throne',\n",
       " '858, tile_roof',\n",
       " '859, toaster',\n",
       " '860, tobacco_shop',\n",
       " '861, toilet_seat',\n",
       " '862, torch',\n",
       " '863, totem_pole',\n",
       " '864, tow_truck',\n",
       " '865, toyshop',\n",
       " '866, tractor',\n",
       " '867, trailer_truck',\n",
       " '868, tray',\n",
       " '869, trench_coat',\n",
       " '870, tricycle',\n",
       " '871, trimaran',\n",
       " '872, tripod',\n",
       " '873, triumphal_arch',\n",
       " '874, trolleybus',\n",
       " '875, trombone',\n",
       " '876, tub',\n",
       " '877, turnstile',\n",
       " '878, typewriter_keyboard',\n",
       " '879, umbrella',\n",
       " '880, unicycle',\n",
       " '881, upright',\n",
       " '882, vacuum',\n",
       " '883, vase',\n",
       " '884, vault',\n",
       " '885, velvet',\n",
       " '886, vending_machine',\n",
       " '887, vestment',\n",
       " '888, viaduct',\n",
       " '889, violin',\n",
       " '890, volleyball',\n",
       " '891, waffle_iron',\n",
       " '892, wall_clock',\n",
       " '893, wallet',\n",
       " '894, wardrobe',\n",
       " '895, warplane',\n",
       " '896, washbasin',\n",
       " '897, washer',\n",
       " '898, water_bottle',\n",
       " '899, water_jug',\n",
       " '900, water_tower',\n",
       " '901, whiskey_jug',\n",
       " '902, whistle',\n",
       " '903, wig',\n",
       " '904, window_screen',\n",
       " '905, window_shade',\n",
       " '906, Windsor_tie',\n",
       " '907, wine_bottle',\n",
       " '908, wing',\n",
       " '909, wok',\n",
       " '910, wooden_spoon',\n",
       " '911, wool',\n",
       " '912, worm_fence',\n",
       " '913, wreck',\n",
       " '914, yawl',\n",
       " '915, yurt',\n",
       " '916, web_site',\n",
       " '917, comic_book',\n",
       " '918, crossword_puzzle',\n",
       " '919, street_sign',\n",
       " '920, traffic_light',\n",
       " '921, book_jacket',\n",
       " '922, menu',\n",
       " '923, plate',\n",
       " '924, guacamole',\n",
       " '925, consomme',\n",
       " '926, hot_pot',\n",
       " '927, trifle',\n",
       " '928, ice_cream',\n",
       " '929, ice_lolly',\n",
       " '930, French_loaf',\n",
       " '931, bagel',\n",
       " '932, pretzel',\n",
       " '933, cheeseburger',\n",
       " '934, hotdog',\n",
       " '935, mashed_potato',\n",
       " '936, head_cabbage',\n",
       " '937, broccoli',\n",
       " '938, cauliflower',\n",
       " '939, zucchini',\n",
       " '940, spaghetti_squash',\n",
       " '941, acorn_squash',\n",
       " '942, butternut_squash',\n",
       " '943, cucumber',\n",
       " '944, artichoke',\n",
       " '945, bell_pepper',\n",
       " '946, cardoon',\n",
       " '947, mushroom',\n",
       " '948, Granny_Smith',\n",
       " '949, strawberry',\n",
       " '950, orange',\n",
       " '951, lemon',\n",
       " '952, fig',\n",
       " '953, pineapple',\n",
       " '954, banana',\n",
       " '955, jackfruit',\n",
       " '956, custard_apple',\n",
       " '957, pomegranate',\n",
       " '958, hay',\n",
       " '959, carbonara',\n",
       " '960, chocolate_sauce',\n",
       " '961, dough',\n",
       " '962, meat_loaf',\n",
       " '963, pizza',\n",
       " '964, potpie',\n",
       " '965, burrito',\n",
       " '966, red_wine',\n",
       " '967, espresso',\n",
       " '968, cup',\n",
       " '969, eggnog',\n",
       " '970, alp',\n",
       " '971, bubble',\n",
       " '972, cliff',\n",
       " '973, coral_reef',\n",
       " '974, geyser',\n",
       " '975, lakeside',\n",
       " '976, promontory',\n",
       " '977, sandbar',\n",
       " '978, seashore',\n",
       " '979, valley',\n",
       " '980, volcano',\n",
       " '981, ballplayer',\n",
       " '982, groom',\n",
       " '983, scuba_diver',\n",
       " '984, rapeseed',\n",
       " '985, daisy',\n",
       " \"986, yellow_lady's_slipper\",\n",
       " '987, corn',\n",
       " '988, acorn',\n",
       " '989, hip',\n",
       " '990, buckeye',\n",
       " '991, coral_fungus',\n",
       " '992, agaric',\n",
       " '993, gyromitra',\n",
       " '994, stinkhorn',\n",
       " '995, earthstar',\n",
       " '996, hen-of-the-woods',\n",
       " '997, bolete',\n",
       " '998, ear',\n",
       " '999, toilet_tissue',\n",
       " ...]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_out = torch.argmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(445)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, indices = torch.sort(out, descending=True)\n",
    "idd = torch.squeeze(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445, bikini\n",
      "838, sunscreen\n",
      "459, brassiere\n",
      "591, handkerchief\n",
      "692, packet\n",
      "529, diaper\n",
      "684, ocarina\n",
      "631, lotion\n",
      "414, backpack\n",
      "709, pencil_box\n"
     ]
    }
   ],
   "source": [
    "# 显示最有可能的n类\n",
    "for i in range(10):\n",
    "    print(classes[idd[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义神经网络\n",
    "该网络有3层\n",
    "\n",
    "- 第一层input layer，有784个神经元（MNIST数据集是28*28的单通道图片，故有784个神经元）\n",
    "- 第二层为hidden_layer，设置为500个神经元\n",
    "- 最后一层是输出层，有10个神经元（10分类任务）\n",
    "- 在第二层之后还有个ReLU函数，进行非线性变换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.1862\n",
      "Epoch [1/3], Loss: 0.3103\n",
      "Epoch [1/3], Loss: 0.3723\n",
      "Epoch [1/3], Loss: 0.3159\n",
      "Epoch [1/3], Loss: 0.2348\n",
      "Epoch [1/3], Loss: 0.2382\n",
      "Epoch [2/3], Loss: 0.0982\n",
      "Epoch [2/3], Loss: 0.1150\n",
      "Epoch [2/3], Loss: 0.1645\n",
      "Epoch [2/3], Loss: 0.1601\n",
      "Epoch [2/3], Loss: 0.1165\n",
      "Epoch [2/3], Loss: 0.1872\n",
      "Epoch [3/3], Loss: 0.0579\n",
      "Epoch [3/3], Loss: 0.0804\n",
      "Epoch [3/3], Loss: 0.0842\n",
      "Epoch [3/3], Loss: 0.0926\n",
      "Epoch [3/3], Loss: 0.0673\n",
      "Epoch [3/3], Loss: 0.1595\n",
      "The accuracy of total 10000 images: 96.67%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(\n",
    "    # root=\"./data\",\n",
    "    root=\"C:\\\\Users\\\\Doiya\\\\Desktop\\\\PythonProject\\\\Pytorch_Lrean\\\\data\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "train_loader = dataloader.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(\n",
    "    # root=\"./data\",\n",
    "    root=\"C:\\\\Users\\\\Doiya\\\\Desktop\\\\PythonProject\\\\Pytorch_Lrean\\\\data\",\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_loader = dataloader.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_num, hidden_num, output_num):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # 隐层\n",
    "        self.fc1 = nn.Linear(input_num, hidden_num)\n",
    "        # 输出层\n",
    "        self.fc2 = nn.Linear(hidden_num, output_num)\n",
    "        # 激活函数\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        # 前向模型\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        y = self.fc2(x)\n",
    "        return y\n",
    "\n",
    "# 训练批次\n",
    "epoches = 3\n",
    "# 学习率learnRate\n",
    "lr = 0.001\n",
    "# 输入层维度\n",
    "input_num = 784\n",
    "# 隐层维度\n",
    "hidden_num = 500\n",
    "# 输出层维度\n",
    "output_num = 10\n",
    "# 选择cpu/gpu\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 初始化模型\n",
    "model = NeuralNet(input_num, hidden_num, output_num)\n",
    "model.to(device)\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# 优化器\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        (images, labels) = data\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, epoches, loss.item()))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"The accuracy of total {} images: {}%\".format(total, 100 * correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：\n",
    "- 预先加载训练集和测试集\n",
    "- 预先定制模型框架，占位符\n",
    "- 初始化训练参数，初始化模型\n",
    "- 开始加载数据集进行训练\n",
    "- 训练结束，调用测试集得出正确率\n",
    "\n",
    "调参：\n",
    "- 不变学习率lr，增加epoches，可以提高准确率 (3->4->5->10):(96.41% ->97.31% -> 97.38% ->97.58%)\n",
    "- 不变epoches，调低学习率lr，会使得拟合速度变慢 (0.001->0.0001->0.00001):(96.41% ->93.1% ->83.8%) 需要增加epoches\n",
    "- 不变epoches，调高学习率lr，会使得拟合速度变快，但却没法达到最优 需要寻找合适的lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10\n",
    "更改训练集为CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/3], Loss: 1.9865\n",
      "Epoch [1/3], Loss: 1.9773\n",
      "Epoch [1/3], Loss: 1.6489\n",
      "Epoch [1/3], Loss: 1.7570\n",
      "Epoch [1/3], Loss: 1.8290\n",
      "Epoch [2/3], Loss: 1.8332\n",
      "Epoch [2/3], Loss: 1.7649\n",
      "Epoch [2/3], Loss: 1.5115\n",
      "Epoch [2/3], Loss: 1.6438\n",
      "Epoch [2/3], Loss: 1.7872\n",
      "Epoch [3/3], Loss: 1.6837\n",
      "Epoch [3/3], Loss: 1.6501\n",
      "Epoch [3/3], Loss: 1.4655\n",
      "Epoch [3/3], Loss: 1.5709\n",
      "Epoch [3/3], Loss: 1.7418\n",
      "The accuracy of total 10000 images: 43.84%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    # root=\"./data\",\n",
    "    root=\"C:\\\\Users\\\\Doiya\\\\Desktop\\\\PythonProject\\\\Pytorch_Lrean\\\\cifar-10-python\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "train_loader = dataloader.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    # root=\"./data\",\n",
    "    root=\"C:\\\\Users\\\\Doiya\\\\Desktop\\\\PythonProject\\\\Pytorch_Lrean\\\\cifar-10-python\",\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_loader = dataloader.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_num, hidden_num, output_num):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_num, hidden_num)\n",
    "        self.fc2 = nn.Linear(hidden_num, output_num)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        y = self.fc2(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "epoches = 3\n",
    "lr = 0.001\n",
    "input_num = 3072\n",
    "hidden_num = 500\n",
    "output_num = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = NeuralNet(input_num, hidden_num, output_num)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        (images, labels) = data\n",
    "        images = images.reshape(-1, 32*32*3).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, epoches, loss.item()))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 32*32*3).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"The accuracy of total {} images: {}%\".format(total, 100 * correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更改模型，改为4层，中间两层隐层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/5], Loss: 1.9782\n",
      "Epoch [1/5], Loss: 1.8332\n",
      "Epoch [1/5], Loss: 1.6163\n",
      "Epoch [1/5], Loss: 1.7119\n",
      "Epoch [1/5], Loss: 1.8233\n",
      "Epoch [2/5], Loss: 1.7197\n",
      "Epoch [2/5], Loss: 1.6535\n",
      "Epoch [2/5], Loss: 1.4919\n",
      "Epoch [2/5], Loss: 1.5751\n",
      "Epoch [2/5], Loss: 1.7088\n",
      "Epoch [3/5], Loss: 1.5537\n",
      "Epoch [3/5], Loss: 1.5297\n",
      "Epoch [3/5], Loss: 1.4098\n",
      "Epoch [3/5], Loss: 1.4532\n",
      "Epoch [3/5], Loss: 1.6331\n",
      "Epoch [4/5], Loss: 1.5043\n",
      "Epoch [4/5], Loss: 1.5009\n",
      "Epoch [4/5], Loss: 1.3734\n",
      "Epoch [4/5], Loss: 1.4408\n",
      "Epoch [4/5], Loss: 1.5663\n",
      "Epoch [5/5], Loss: 1.4573\n",
      "Epoch [5/5], Loss: 1.4316\n",
      "Epoch [5/5], Loss: 1.3527\n",
      "Epoch [5/5], Loss: 1.3839\n",
      "Epoch [5/5], Loss: 1.4940\n",
      "The accuracy of total 10000 images: 48.59%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    # root=\"./data\",\n",
    "    root=\"C:\\\\Users\\\\Doiya\\\\Desktop\\\\PythonProject\\\\Pytorch_Lrean\\\\cifar-10-python\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "train_loader = dataloader.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    # root=\"./data\",\n",
    "    root=\"C:\\\\Users\\\\Doiya\\\\Desktop\\\\PythonProject\\\\Pytorch_Lrean\\\\cifar-10-python\",\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_loader = dataloader.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_num, hidden_num, output_num):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_num, hidden1_num)\n",
    "        self.fc2 = nn.Linear(hidden1_num, hidden2_num)\n",
    "        self.fc3 = nn.Linear(hidden2_num, output_num)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        y = self.fc3(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "epoches = 5\n",
    "lr = 0.001\n",
    "input_num = 3072\n",
    "hidden1_num = 1500\n",
    "hidden2_num = 500\n",
    "output_num = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = NeuralNet(input_num, hidden_num, output_num)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        (images, labels) = data\n",
    "        images = images.reshape(-1, 32*32*3).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, epoches, loss.item()))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 32*32*3).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"The accuracy of total {} images: {}%\".format(total, 100 * correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "总结：\n",
    "- 修改模型，增加隐层，并没有使得精度发生显著变化\n",
    "- 修改参数，调整lr，并没有使得精度发生显著变化，甚至变小\n",
    "- 修改参数，增加epoches，可以增加一点点精度\n",
    "\n",
    "调参，提高准确率\n",
    "- 增加epoches\n",
    "- 调整lr\n",
    "- 增加隐层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再增加一层隐层，测试是否能够提高精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Epoch [1/50], Loss: 2.0392\n",
      "Epoch [1/50], Loss: 1.8909\n",
      "Epoch [1/50], Loss: 1.6834\n",
      "Epoch [1/50], Loss: 1.7883\n",
      "Epoch [1/50], Loss: 1.8436\n",
      "Epoch [2/50], Loss: 1.7776\n",
      "Epoch [2/50], Loss: 1.7182\n",
      "Epoch [2/50], Loss: 1.5224\n",
      "Epoch [2/50], Loss: 1.5778\n",
      "Epoch [2/50], Loss: 1.7894\n",
      "Epoch [3/50], Loss: 1.5746\n",
      "Epoch [3/50], Loss: 1.7027\n",
      "Epoch [3/50], Loss: 1.4466\n",
      "Epoch [3/50], Loss: 1.4558\n",
      "Epoch [3/50], Loss: 1.6349\n",
      "Epoch [4/50], Loss: 1.5273\n",
      "Epoch [4/50], Loss: 1.6074\n",
      "Epoch [4/50], Loss: 1.4111\n",
      "Epoch [4/50], Loss: 1.3731\n",
      "Epoch [4/50], Loss: 1.6110\n",
      "Epoch [5/50], Loss: 1.5292\n",
      "Epoch [5/50], Loss: 1.5668\n",
      "Epoch [5/50], Loss: 1.3803\n",
      "Epoch [5/50], Loss: 1.3194\n",
      "Epoch [5/50], Loss: 1.5253\n",
      "Epoch [6/50], Loss: 1.4534\n",
      "Epoch [6/50], Loss: 1.4851\n",
      "Epoch [6/50], Loss: 1.3714\n",
      "Epoch [6/50], Loss: 1.2876\n",
      "Epoch [6/50], Loss: 1.5336\n",
      "Epoch [7/50], Loss: 1.5158\n",
      "Epoch [7/50], Loss: 1.4956\n",
      "Epoch [7/50], Loss: 1.3330\n",
      "Epoch [7/50], Loss: 1.3136\n",
      "Epoch [7/50], Loss: 1.5032\n",
      "Epoch [8/50], Loss: 1.4503\n",
      "Epoch [8/50], Loss: 1.4912\n",
      "Epoch [8/50], Loss: 1.2573\n",
      "Epoch [8/50], Loss: 1.2639\n",
      "Epoch [8/50], Loss: 1.4328\n",
      "Epoch [9/50], Loss: 1.4266\n",
      "Epoch [9/50], Loss: 1.4756\n",
      "Epoch [9/50], Loss: 1.2535\n",
      "Epoch [9/50], Loss: 1.1375\n",
      "Epoch [9/50], Loss: 1.4070\n",
      "Epoch [10/50], Loss: 1.3337\n",
      "Epoch [10/50], Loss: 1.4352\n",
      "Epoch [10/50], Loss: 1.1437\n",
      "Epoch [10/50], Loss: 1.2121\n",
      "Epoch [10/50], Loss: 1.3637\n",
      "Epoch [11/50], Loss: 1.2962\n",
      "Epoch [11/50], Loss: 1.4360\n",
      "Epoch [11/50], Loss: 1.1755\n",
      "Epoch [11/50], Loss: 1.2084\n",
      "Epoch [11/50], Loss: 1.3756\n",
      "Epoch [12/50], Loss: 1.2637\n",
      "Epoch [12/50], Loss: 1.4346\n",
      "Epoch [12/50], Loss: 1.1833\n",
      "Epoch [12/50], Loss: 1.2281\n",
      "Epoch [12/50], Loss: 1.2908\n",
      "Epoch [13/50], Loss: 1.2389\n",
      "Epoch [13/50], Loss: 1.3942\n",
      "Epoch [13/50], Loss: 1.0830\n",
      "Epoch [13/50], Loss: 1.1521\n",
      "Epoch [13/50], Loss: 1.2590\n",
      "Epoch [14/50], Loss: 1.2453\n",
      "Epoch [14/50], Loss: 1.2773\n",
      "Epoch [14/50], Loss: 1.0923\n",
      "Epoch [14/50], Loss: 0.9822\n",
      "Epoch [14/50], Loss: 1.1880\n",
      "Epoch [15/50], Loss: 1.2433\n",
      "Epoch [15/50], Loss: 1.3150\n",
      "Epoch [15/50], Loss: 1.0181\n",
      "Epoch [15/50], Loss: 1.0165\n",
      "Epoch [15/50], Loss: 1.1573\n",
      "Epoch [16/50], Loss: 1.3422\n",
      "Epoch [16/50], Loss: 1.3264\n",
      "Epoch [16/50], Loss: 0.9900\n",
      "Epoch [16/50], Loss: 1.0084\n",
      "Epoch [16/50], Loss: 1.0928\n",
      "Epoch [17/50], Loss: 1.2546\n",
      "Epoch [17/50], Loss: 1.3993\n",
      "Epoch [17/50], Loss: 1.0031\n",
      "Epoch [17/50], Loss: 1.0194\n",
      "Epoch [17/50], Loss: 1.0477\n",
      "Epoch [18/50], Loss: 1.2295\n",
      "Epoch [18/50], Loss: 1.3024\n",
      "Epoch [18/50], Loss: 0.9660\n",
      "Epoch [18/50], Loss: 1.1255\n",
      "Epoch [18/50], Loss: 0.9918\n",
      "Epoch [19/50], Loss: 1.2365\n",
      "Epoch [19/50], Loss: 1.3146\n",
      "Epoch [19/50], Loss: 0.9272\n",
      "Epoch [19/50], Loss: 0.9820\n",
      "Epoch [19/50], Loss: 1.0150\n",
      "Epoch [20/50], Loss: 1.2386\n",
      "Epoch [20/50], Loss: 1.3272\n",
      "Epoch [20/50], Loss: 0.9020\n",
      "Epoch [20/50], Loss: 1.0113\n",
      "Epoch [20/50], Loss: 0.9676\n",
      "Epoch [21/50], Loss: 1.2627\n",
      "Epoch [21/50], Loss: 1.1132\n",
      "Epoch [21/50], Loss: 0.9920\n",
      "Epoch [21/50], Loss: 0.9125\n",
      "Epoch [21/50], Loss: 1.0137\n",
      "Epoch [22/50], Loss: 1.2712\n",
      "Epoch [22/50], Loss: 1.1826\n",
      "Epoch [22/50], Loss: 0.9119\n",
      "Epoch [22/50], Loss: 0.8587\n",
      "Epoch [22/50], Loss: 1.0270\n",
      "Epoch [23/50], Loss: 1.1604\n",
      "Epoch [23/50], Loss: 1.2157\n",
      "Epoch [23/50], Loss: 0.8966\n",
      "Epoch [23/50], Loss: 0.8031\n",
      "Epoch [23/50], Loss: 1.0382\n",
      "Epoch [24/50], Loss: 1.2292\n",
      "Epoch [24/50], Loss: 1.1772\n",
      "Epoch [24/50], Loss: 0.8553\n",
      "Epoch [24/50], Loss: 0.7470\n",
      "Epoch [24/50], Loss: 1.0609\n",
      "Epoch [25/50], Loss: 1.1258\n",
      "Epoch [25/50], Loss: 1.1950\n",
      "Epoch [25/50], Loss: 0.8426\n",
      "Epoch [25/50], Loss: 0.7187\n",
      "Epoch [25/50], Loss: 0.9169\n",
      "Epoch [26/50], Loss: 1.0827\n",
      "Epoch [26/50], Loss: 1.1474\n",
      "Epoch [26/50], Loss: 0.7930\n",
      "Epoch [26/50], Loss: 0.7462\n",
      "Epoch [26/50], Loss: 0.8197\n",
      "Epoch [27/50], Loss: 1.1037\n",
      "Epoch [27/50], Loss: 1.1466\n",
      "Epoch [27/50], Loss: 0.8671\n",
      "Epoch [27/50], Loss: 0.7502\n",
      "Epoch [27/50], Loss: 0.8419\n",
      "Epoch [28/50], Loss: 0.9955\n",
      "Epoch [28/50], Loss: 1.1564\n",
      "Epoch [28/50], Loss: 0.7906\n",
      "Epoch [28/50], Loss: 0.7945\n",
      "Epoch [28/50], Loss: 0.8291\n",
      "Epoch [29/50], Loss: 1.1565\n",
      "Epoch [29/50], Loss: 1.1980\n",
      "Epoch [29/50], Loss: 0.8622\n",
      "Epoch [29/50], Loss: 0.8167\n",
      "Epoch [29/50], Loss: 1.0331\n",
      "Epoch [30/50], Loss: 1.1444\n",
      "Epoch [30/50], Loss: 1.0628\n",
      "Epoch [30/50], Loss: 0.8318\n",
      "Epoch [30/50], Loss: 0.7739\n",
      "Epoch [30/50], Loss: 1.0304\n",
      "Epoch [31/50], Loss: 1.0292\n",
      "Epoch [31/50], Loss: 1.1041\n",
      "Epoch [31/50], Loss: 0.8973\n",
      "Epoch [31/50], Loss: 1.0070\n",
      "Epoch [31/50], Loss: 1.0615\n",
      "Epoch [32/50], Loss: 0.9569\n",
      "Epoch [32/50], Loss: 1.1429\n",
      "Epoch [32/50], Loss: 0.8875\n",
      "Epoch [32/50], Loss: 0.8428\n",
      "Epoch [32/50], Loss: 0.7863\n",
      "Epoch [33/50], Loss: 1.0931\n",
      "Epoch [33/50], Loss: 1.0101\n",
      "Epoch [33/50], Loss: 0.8156\n",
      "Epoch [33/50], Loss: 0.8297\n",
      "Epoch [33/50], Loss: 0.8611\n",
      "Epoch [34/50], Loss: 1.0303\n",
      "Epoch [34/50], Loss: 0.9588\n",
      "Epoch [34/50], Loss: 0.7385\n",
      "Epoch [34/50], Loss: 0.7755\n",
      "Epoch [34/50], Loss: 0.7564\n",
      "Epoch [35/50], Loss: 1.0156\n",
      "Epoch [35/50], Loss: 1.0101\n",
      "Epoch [35/50], Loss: 0.7670\n",
      "Epoch [35/50], Loss: 0.7084\n",
      "Epoch [35/50], Loss: 0.8552\n",
      "Epoch [36/50], Loss: 1.0397\n",
      "Epoch [36/50], Loss: 1.0350\n",
      "Epoch [36/50], Loss: 0.8202\n",
      "Epoch [36/50], Loss: 0.7438\n",
      "Epoch [36/50], Loss: 0.8967\n",
      "Epoch [37/50], Loss: 0.9643\n",
      "Epoch [37/50], Loss: 0.9434\n",
      "Epoch [37/50], Loss: 0.7437\n",
      "Epoch [37/50], Loss: 0.8399\n",
      "Epoch [37/50], Loss: 0.9461\n",
      "Epoch [38/50], Loss: 1.0724\n",
      "Epoch [38/50], Loss: 1.1219\n",
      "Epoch [38/50], Loss: 0.7823\n",
      "Epoch [38/50], Loss: 0.9263\n",
      "Epoch [38/50], Loss: 1.0643\n",
      "Epoch [39/50], Loss: 1.0109\n",
      "Epoch [39/50], Loss: 0.9450\n",
      "Epoch [39/50], Loss: 0.7426\n",
      "Epoch [39/50], Loss: 0.9110\n",
      "Epoch [39/50], Loss: 0.9728\n",
      "Epoch [40/50], Loss: 1.0020\n",
      "Epoch [40/50], Loss: 0.9588\n",
      "Epoch [40/50], Loss: 0.8160\n",
      "Epoch [40/50], Loss: 0.9129\n",
      "Epoch [40/50], Loss: 1.0041\n",
      "Epoch [41/50], Loss: 1.1040\n",
      "Epoch [41/50], Loss: 0.9870\n",
      "Epoch [41/50], Loss: 0.8838\n",
      "Epoch [41/50], Loss: 0.9590\n",
      "Epoch [41/50], Loss: 0.8837\n",
      "Epoch [42/50], Loss: 0.9920\n",
      "Epoch [42/50], Loss: 0.9908\n",
      "Epoch [42/50], Loss: 0.7167\n",
      "Epoch [42/50], Loss: 0.8715\n",
      "Epoch [42/50], Loss: 0.8917\n",
      "Epoch [43/50], Loss: 0.9384\n",
      "Epoch [43/50], Loss: 0.9991\n",
      "Epoch [43/50], Loss: 0.7235\n",
      "Epoch [43/50], Loss: 0.8509\n",
      "Epoch [43/50], Loss: 0.9426\n",
      "Epoch [44/50], Loss: 0.7928\n",
      "Epoch [44/50], Loss: 1.0860\n",
      "Epoch [44/50], Loss: 0.7337\n",
      "Epoch [44/50], Loss: 0.6786\n",
      "Epoch [44/50], Loss: 0.8277\n",
      "Epoch [45/50], Loss: 0.7707\n",
      "Epoch [45/50], Loss: 0.9440\n",
      "Epoch [45/50], Loss: 0.6278\n",
      "Epoch [45/50], Loss: 0.7913\n",
      "Epoch [45/50], Loss: 0.8654\n",
      "Epoch [46/50], Loss: 0.8741\n",
      "Epoch [46/50], Loss: 0.9480\n",
      "Epoch [46/50], Loss: 0.6143\n",
      "Epoch [46/50], Loss: 0.8133\n",
      "Epoch [46/50], Loss: 0.7938\n",
      "Epoch [47/50], Loss: 0.6782\n",
      "Epoch [47/50], Loss: 0.7801\n",
      "Epoch [47/50], Loss: 0.6691\n",
      "Epoch [47/50], Loss: 0.6937\n",
      "Epoch [47/50], Loss: 0.7381\n",
      "Epoch [48/50], Loss: 0.7192\n",
      "Epoch [48/50], Loss: 0.8655\n",
      "Epoch [48/50], Loss: 0.6992\n",
      "Epoch [48/50], Loss: 0.7149\n",
      "Epoch [48/50], Loss: 0.7401\n",
      "Epoch [49/50], Loss: 0.8445\n",
      "Epoch [49/50], Loss: 0.8914\n",
      "Epoch [49/50], Loss: 0.6221\n",
      "Epoch [49/50], Loss: 0.7861\n",
      "Epoch [49/50], Loss: 0.8256\n",
      "Epoch [50/50], Loss: 0.8589\n",
      "Epoch [50/50], Loss: 0.8524\n",
      "Epoch [50/50], Loss: 0.6874\n",
      "Epoch [50/50], Loss: 0.8814\n",
      "Epoch [50/50], Loss: 0.8241\n",
      "The accuracy of total 10000 images: 45.16%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data.dataloader as dataloader\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(\n",
    "    # root=\"./data\",\n",
    "    root=\"C:\\\\Users\\\\Doiya\\\\Desktop\\\\PythonProject\\\\Pytorch_Lrean\\\\cifar-10-python\",\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "train_loader = dataloader.DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "test_set = torchvision.datasets.CIFAR10(\n",
    "    # root=\"./data\",\n",
    "    root=\"C:\\\\Users\\\\Doiya\\\\Desktop\\\\PythonProject\\\\Pytorch_Lrean\\\\cifar-10-python\",\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "test_loader = dataloader.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=100,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "class NeuralNet(nn.Module):\n",
    "\n",
    "    def __init__(self, input_num, hidden_num, output_num):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_num, hidden1_num)\n",
    "        self.fc2 = nn.Linear(hidden1_num, hidden2_num)\n",
    "        self.fc3 = nn.Linear(hidden2_num, hidden3_num)\n",
    "        self.fc4 = nn.Linear(hidden3_num, output_num)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        y = self.fc4(x)\n",
    "        return y\n",
    "\n",
    "\n",
    "epoches = 50\n",
    "lr = 0.001\n",
    "input_num = 3072\n",
    "hidden1_num = 2000\n",
    "hidden2_num = 1000\n",
    "hidden3_num = 500\n",
    "output_num = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = NeuralNet(input_num, hidden_num, output_num)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    for i, data in enumerate(train_loader):\n",
    "        (images, labels) = data\n",
    "        images = images.reshape(-1, 32*32*3).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Loss: {:.4f}'\n",
    "                  .format(epoch + 1, epoches, loss.item()))\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 32*32*3).to(device)\n",
    "        labels = labels.to(device)\n",
    "        output = model(images)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"The accuracy of total {} images: {}%\".format(total, 100 * correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结论：\n",
    "- 即使模型隐层越多，epoches增加到50批次，loss下降到1以下，精度也没有改变，所以问题不是参数的问题，而是模型的问题，激活函数没起到很好的作用。\n",
    "- 目前还没找到很好的解决办法，还得继续学习。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "收获\n",
    "- 通过已训练的模型，加载预训练的参数，进行神经网络的初使用，通过使用图片来得到预测的分类，感受到神经网络运作\n",
    "- 自己一步一步的搭建神经网络，使用已有的训练集进行模型训练，得到自己的神经网络\n",
    "- 调参的体验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PytorchLearn]",
   "language": "python",
   "name": "conda-env-PytorchLearn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
